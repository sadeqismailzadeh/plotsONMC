{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..\\..\\..\\output\\2024.09.02 10-13-18_NonEquilibrium_Analyzed\n",
      "3\n",
      "['2023.11.12_16-37-14_MacIsaac_Tr_L=32_thread=4_MCs=4.0e+00_ens=10000_Hist_T=0.850000', '2023.11.12_18-04-09_MacIsaac_Tr_L=64_thread=4_MCs=4.0e+00_ens=10000_Hist_T=0.850000', '2023.11.14_18-22-08_MacIsaac_Tr_L=128_thread=4_MCs=4.0e+00_ens=10000_Hist_T=0.850000']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "\n",
    "\n",
    "date_time_string = datetime.now().strftime('%Y.%m.%d %H-%M-%S')\n",
    "InputPath = os.path.join('..','..', '..', 'inputNonEquilibriumRaw')\n",
    "CopyPath = os.path.join('..','..', '..', 'copied', f'{date_time_string}_NonEquilibrium_Copied')\n",
    "OutputPath= os.path.join('..','..','..', 'output', f'{date_time_string}_NonEquilibrium_Analyzed')\n",
    "os.makedirs(OutputPath, exist_ok=True)\n",
    "print(OutputPath)\n",
    "\n",
    "def list_directories(path):\n",
    "    return [name for name in os.listdir(path) if os.path.isdir(os.path.join(path, name))]\n",
    "    # return [os.path.join(path, name) for name in os.listdir(path) if os.path.isdir(os.path.join(path, name))]\n",
    "\n",
    "\n",
    "directories = list_directories(InputPath)\n",
    "print(len(directories))\n",
    "print(directories)\n",
    "\n",
    "# Open a text file in write mode\n",
    "with open(os.path.join(OutputPath, 'SamplesInfo.txt'), 'w') as file:\n",
    "    # Iterate over the list and write each item to the file\n",
    "    for item in directories:\n",
    "        file.write(item + '\\n')  # Add a newline after each item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy the directories into a tree structure based on their \"L\" and \"T\" values\n",
    "import os\n",
    "import re\n",
    "import h5py\n",
    "import shutil\n",
    "\n",
    "for directory in directories:\n",
    "    SubInputPath = os.path.join(InputPath , directory)\n",
    "    L_value = re.search('L=(\\d+)', directory).group(1)\n",
    "    T_value = re.search('T=(\\d+\\.\\d+)', directory).group(1)\n",
    "\n",
    "\n",
    "    i = 1\n",
    "    SubNewPath = os.path.join(CopyPath, L_value, T_value, f\"{i}\")\n",
    "    while os.path.exists(SubNewPath):\n",
    "        i += 1\n",
    "        SubNewPath = os.path.join(CopyPath, L_value, T_value, f\"{i}\")\n",
    "\n",
    "    os.makedirs(os.path.dirname(SubNewPath), exist_ok=True)\n",
    "    shutil.copytree(SubInputPath, SubNewPath)\n",
    "\n",
    "    # Now, store L_value and T_value in an HDF5 file\n",
    "    hdf5_file_path = os.path.join(SubNewPath, 'metadata.h5')\n",
    "    if not os.path.exists(hdf5_file_path):\n",
    "        with h5py.File(hdf5_file_path, 'w') as hdf5_file:\n",
    "            hdf5_file.create_dataset('SystemLength', data=int(L_value))\n",
    "            hdf5_file.create_dataset('Temperature', data=float(T_value))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['..\\\\..\\\\..\\\\copied\\\\2024.09.02 10-13-18_NonEquilibrium_Copied\\\\128\\\\0.850000', '..\\\\..\\\\..\\\\copied\\\\2024.09.02 10-13-18_NonEquilibrium_Copied\\\\32\\\\0.850000', '..\\\\..\\\\..\\\\copied\\\\2024.09.02 10-13-18_NonEquilibrium_Copied\\\\64\\\\0.850000']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def list_directories_at_level(root_directory, level):\n",
    "    level_directories = []\n",
    "\n",
    "    for root, dirs, files in os.walk(root_directory):\n",
    "        # Check the level of the current directory\n",
    "        current_level = root.count(os.sep) - root_directory.count(os.sep)\n",
    "\n",
    "        if current_level == level:\n",
    "            # Append subdirectories at the specified level to the list\n",
    "            level_directories.extend(os.path.join(root, directory) for directory in dirs)\n",
    "\n",
    "        # Avoid descending into subdirectories to keep it at the specified level\n",
    "        if current_level >= level:\n",
    "            dirs.clear()\n",
    "\n",
    "    return level_directories\n",
    "\n",
    "level_two_directories = list_directories_at_level(CopyPath, 1)\n",
    "\n",
    "# Print the list of directories at level 1\n",
    "print(level_two_directories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['128\\\\0.850000', '32\\\\0.850000', '64\\\\0.850000']\n"
     ]
    }
   ],
   "source": [
    "# List to store the copied directories\n",
    "CopiedDirectories = []\n",
    "\n",
    "# Iterate over each source directory in level two directories\n",
    "for source_directory in level_two_directories:\n",
    "    # Split the source directory path\n",
    "    split_directory = source_directory.split(os.path.sep)\n",
    "    \n",
    "    # Get the last two directories from the split directory path\n",
    "    last_two_directories = split_directory[-2:]\n",
    "    \n",
    "    # Join the last two directories and add to the list\n",
    "    CopiedDirectories.append(os.path.join(*last_two_directories))\n",
    "\n",
    "# Print the copied directories\n",
    "print(CopiedDirectories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty directory created at: ..\\..\\..\\output\\2024.09.02 10-13-18_NonEquilibrium_Analyzed\\128\\0.850000\n",
      "Empty directory created at: ..\\..\\..\\output\\2024.09.02 10-13-18_NonEquilibrium_Analyzed\\32\\0.850000\n",
      "Empty directory created at: ..\\..\\..\\output\\2024.09.02 10-13-18_NonEquilibrium_Analyzed\\64\\0.850000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "for CopiedDirectory in CopiedDirectories:\n",
    "    SubOutputPath = os.path.join(OutputPath, CopiedDirectory)\n",
    "    # Check if the target directory already exists, if not, create it\n",
    "    if not os.path.exists(SubOutputPath):\n",
    "        os.makedirs(SubOutputPath)\n",
    "        print(f\"Empty directory created at: {SubOutputPath}\")\n",
    "    else:\n",
    "        print(f\"Directory already exists: {SubOutputPath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "directory = 128\\0.850000\n",
      "..\\..\\..\\copied\\2024.09.02 10-13-18_NonEquilibrium_Copied\\128\\0.850000\\1 exists\n",
      "Nensemble = 6600\n",
      "directory = 32\\0.850000\n",
      "..\\..\\..\\copied\\2024.09.02 10-13-18_NonEquilibrium_Copied\\32\\0.850000\\1 exists\n",
      "Nensemble = 6600\n",
      "directory = 64\\0.850000\n",
      "..\\..\\..\\copied\\2024.09.02 10-13-18_NonEquilibrium_Copied\\64\\0.850000\\1 exists\n",
      "Nensemble = 6600\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import time\n",
    "import re\n",
    "\n",
    "Nbins = 5\n",
    "\n",
    "start_time = time.time()\n",
    "for CopiedDirectory in CopiedDirectories:\n",
    "    print(f\"directory = {CopiedDirectory}\")\n",
    "    # SubInputPath = os.path.join(CopyPath , directory, \"1\")\n",
    "    SubOutputPath = os.path.join(OutputPath, CopiedDirectory)\n",
    "    # os.makedirs(SubOutputPath, exist_ok=True)\n",
    "\n",
    "    ResultsFiles = []\n",
    "    metadatas = []\n",
    "    # List of your HDF5 files\n",
    "    counterDirectories = 1\n",
    "    SubInputPath = os.path.join(CopyPath , CopiedDirectory, f\"{counterDirectories}\")\n",
    "    while os.path.exists(SubInputPath):\n",
    "        print(f\"{SubInputPath} exists\")\n",
    "        ResultsFile = h5py.File(os.path.join(SubInputPath, 'Results.h5'), 'r')\n",
    "        metadata = h5py.File(os.path.join(SubInputPath, 'metadata.h5'), 'r')\n",
    "        ResultsFiles.append(ResultsFile)\n",
    "        metadatas.append(metadata)\n",
    "        counterDirectories += 1\n",
    "        SubInputPath = os.path.join(CopyPath , CopiedDirectory, f\"{counterDirectories}\")\n",
    "\n",
    "\n",
    "    # print(NensembleExpexted)\n",
    "    Temporary_results = ResultsFiles[0][('/' + '0' + '/TimeSeries/Equilibration/Magnetization')]\n",
    "    \n",
    "    \n",
    "    # Calculate the size of each subset\n",
    "    m1timeSum = np.zeros((len(Temporary_results), Nbins))\n",
    "    m2timeSum = np.zeros((len(Temporary_results), Nbins))\n",
    "    m3timeSum = np.zeros((len(Temporary_results), Nbins))\n",
    "    m4timeSum = np.zeros((len(Temporary_results), Nbins))\n",
    "    E1timeSum = np.zeros((len(Temporary_results), Nbins))\n",
    "    E2timeSum = np.zeros((len(Temporary_results), Nbins))\n",
    "    E3timeSum = np.zeros((len(Temporary_results), Nbins))\n",
    "    E4timeSum = np.zeros((len(Temporary_results), Nbins))\n",
    "    m1E1timeSum = np.zeros((len(Temporary_results), Nbins))\n",
    "    QttimeSum = np.zeros((len(Temporary_results), Nbins))\n",
    "\n",
    "\n",
    "    NensembleExpected = 0\n",
    "    for ResultsFile in ResultsFiles: \n",
    "        NensembleExpectedFile = ResultsFile['Nensemble']\n",
    "        NensembleExpected += NensembleExpectedFile[...].astype(int)\n",
    "\n",
    "    SystemLength = metadatas[0]['SystemLength'][...].astype(int)\n",
    "    Temperature  = metadatas[0]['Temperature'][...].astype(float)\n",
    "    subset_size = NensembleExpected // Nbins\n",
    "    BinSize = np.zeros((Nbins))\n",
    "\n",
    "\n",
    "    # Initialize counters\n",
    "    # counter = 0\n",
    "    Nensemble = 0\n",
    "    Bin_counter = 0\n",
    "    Bin_index = 0\n",
    "\n",
    "    # Loop over each file\n",
    "    for ResultsFile in ResultsFiles:\n",
    "        EnsembleIndex = 0\n",
    "        EnsembleIndexStr = str(EnsembleIndex)\n",
    "        while ('/' + EnsembleIndexStr + '/TimeSeries/Equilibration/Magnetization') in ResultsFile:\n",
    "            mtimeEnsemble = ResultsFile[('/' + EnsembleIndexStr + '/TimeSeries/Equilibration/Magnetization')]\n",
    "            EtimeEnsemble = ResultsFile[('/' + EnsembleIndexStr + '/TimeSeries/Equilibration/Energy')]\n",
    "            m1timeSum[: ,Bin_index] += mtimeEnsemble\n",
    "            m2timeSum[: ,Bin_index] += np.square(mtimeEnsemble)\n",
    "            m3timeSum[: ,Bin_index] += np.power(mtimeEnsemble, 3)\n",
    "            m4timeSum[: ,Bin_index] += np.power(mtimeEnsemble, 4)\n",
    "            E1timeSum[: ,Bin_index] += EtimeEnsemble\n",
    "            E2timeSum[: ,Bin_index] += np.square(EtimeEnsemble)\n",
    "            E3timeSum[: ,Bin_index] += np.power(EtimeEnsemble, 3)\n",
    "            E4timeSum[: ,Bin_index] += np.power(EtimeEnsemble, 4)\n",
    "            m1E1timeSum[: ,Bin_index] += np.array(mtimeEnsemble) * np.array(EtimeEnsemble)\n",
    "            QttimeSum[: ,Bin_index] += mtimeEnsemble[0] * mtimeEnsemble\n",
    "            Nensemble += 1\n",
    "            # counter += 1\n",
    "            EnsembleIndex += 1\n",
    "            EnsembleIndexStr = str(EnsembleIndex)\n",
    "            Bin_counter += 1\n",
    "            if Bin_counter == subset_size:\n",
    "                BinSize[Bin_index] = Bin_counter\n",
    "                Bin_index += 1\n",
    "                # Reset the counters\n",
    "                Bin_counter = 0\n",
    "                if Bin_index == Nbins:\n",
    "                    break\n",
    "\n",
    "    # If there are remaining values\n",
    "    if Bin_counter > 0:\n",
    "        BinSize[Bin_index] = Bin_counter\n",
    "        # Bin_index += 1\n",
    "        # Reset the counters\n",
    "        Bin_counter = 0\n",
    "        \n",
    "    print(f\"Nensemble = {Nensemble}\")\n",
    "    m1timeBins = m1timeSum / BinSize\n",
    "    m2timeBins = m2timeSum / BinSize\n",
    "    m3timeBins = m3timeSum / BinSize\n",
    "    m4timeBins = m4timeSum / BinSize\n",
    "    E1timeBins = E1timeSum / BinSize\n",
    "    E2timeBins = E2timeSum / BinSize\n",
    "    E3timeBins = E3timeSum / BinSize\n",
    "    E4timeBins = E4timeSum / BinSize\n",
    "    m1E1timeBins = m1E1timeSum / BinSize\n",
    "    QtBins = QttimeSum / BinSize\n",
    "    HeatCapacityBins = np.zeros((len(Temporary_results), Nbins))\n",
    "    SusceptibilityBins = np.zeros((len(Temporary_results), Nbins))\n",
    "    mDerBins = np.zeros((len(Temporary_results), Nbins))\n",
    "    Binder2Bins = np.zeros((len(Temporary_results), Nbins))\n",
    "    SystemSize= SystemLength ** 2\n",
    "    N = SystemSize\n",
    "    T = Temperature\n",
    "    for i in range(m1timeBins.shape[1]):\n",
    "        m1 = m1timeBins[:, i]\n",
    "        m2 = m2timeBins[:, i]\n",
    "        m3 = m3timeBins[:, i]\n",
    "        m4 = m4timeBins[:, i]\n",
    "        E1 = E1timeBins[:, i]\n",
    "        E2 = E2timeBins[:, i]\n",
    "        E3 = E3timeBins[:, i]\n",
    "        E4 = E4timeBins[:, i]\n",
    "        m1E1 = m1E1timeBins[:, i]\n",
    "        HeatCapacityBins[:, i] = E2 / (E1 ** 2) - 1\n",
    "        SusceptibilityBins[:, i] = m2 / (m1 ** 2) - 1\n",
    "        mDerBins[:, i] = m1E1 / (m1 * E1) - 1\n",
    "        Binder2Bins[:, i] = m2 / (m1 ** 2) - 1\n",
    "\n",
    "    SaveFile= h5py.File(os.path.join(SubOutputPath, 'Results.h5'), 'w')\n",
    "    for i in range(m1timeBins.shape[1]):\n",
    "        SaveFile.create_dataset(f'/mtime1Bins/{i}', data=m1timeBins[:, i])\n",
    "        SaveFile.create_dataset(f'/mtime2Bins/{i}', data=m2timeBins[:, i])\n",
    "        SaveFile.create_dataset(f'/mtime3Bins/{i}', data=m3timeBins[:, i])\n",
    "        SaveFile.create_dataset(f'/mtime4Bins/{i}', data=m4timeBins[:, i])\n",
    "        SaveFile.create_dataset(f'/Etime1Bins/{i}', data=E1timeBins[:, i])\n",
    "        SaveFile.create_dataset(f'/Etime2Bins/{i}', data=E2timeBins[:, i])\n",
    "        SaveFile.create_dataset(f'/Etime3Bins/{i}', data=E3timeBins[:, i])\n",
    "        SaveFile.create_dataset(f'/Etime4Bins/{i}', data=E4timeBins[:, i])\n",
    "        SaveFile.create_dataset(f'/m1E1timeBins/{i}', data=m1E1timeBins[:, i])\n",
    "\n",
    "    def getMeanErr(ParamBins):\n",
    "        MeanParam= np.mean(ParamBins, axis=1)\n",
    "        ErrorParam = np.std(ParamBins, axis=1)/ np.sqrt(ParamBins.shape[1])\n",
    "        return MeanParam, ErrorParam\n",
    "\n",
    "    MeanMagnetization, ErrorMagnetization  = getMeanErr(m1timeBins / N)\n",
    "    MeanEnergy, ErrorEnergy  = getMeanErr(E1timeBins / N)\n",
    "    MeanHeatCapacity, ErrorHeatCapacity  = getMeanErr(HeatCapacityBins)\n",
    "    MeanSusceptibility, ErrorSusceptibility = getMeanErr(SusceptibilityBins)\n",
    "    Mean_mDer, Error_mDer = getMeanErr(mDerBins)\n",
    "    MeanBinder2, ErrorBinder2 = getMeanErr(Binder2Bins)\n",
    "    MeanQt, ErrorQt = getMeanErr(QtBins)\n",
    "\n",
    "    SaveFile.create_dataset('/Magnetization/mean', data=MeanMagnetization)\n",
    "    SaveFile.create_dataset('/Magnetization/error', data=ErrorMagnetization)\n",
    "    SaveFile.create_dataset('/Energy/mean', data=MeanEnergy)\n",
    "    SaveFile.create_dataset('/Energy/error', data=ErrorEnergy)\n",
    "    SaveFile.create_dataset('/HeatCapacity/mean', data=MeanHeatCapacity)\n",
    "    SaveFile.create_dataset('/HeatCapacity/error', data=ErrorHeatCapacity)\n",
    "    SaveFile.create_dataset('/Susceptibility/mean', data=MeanSusceptibility)\n",
    "    SaveFile.create_dataset('/Susceptibility/error', data=ErrorSusceptibility)\n",
    "    SaveFile.create_dataset('/mDer/mean', data=Mean_mDer)\n",
    "    SaveFile.create_dataset('/mDer/error', data=Error_mDer)\n",
    "    SaveFile.create_dataset('/Binder/mean', data=MeanBinder2)\n",
    "    SaveFile.create_dataset('/Binder/error', data=ErrorBinder2)\n",
    "    SaveFile.create_dataset('/Qt/mean', data=MeanQt)\n",
    "    SaveFile.create_dataset('/Qt/error', data=ErrorQt)\n",
    "    SaveFile.create_dataset('/Temperature', data=Temperature)\n",
    "    SaveFile.create_dataset('/SystemLength', data=SystemLength)\n",
    "    SaveFile.create_dataset('/SystemSize', data=SystemSize)\n",
    "    SaveFile.create_dataset('/Nensemble', data=Nensemble)\n",
    "    for ResultsFile in ResultsFiles:\n",
    "        ResultsFile.close()\n",
    "    for metadata in metadatas:\n",
    "        metadata.close()\n",
    "    SaveFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(CopyPath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
